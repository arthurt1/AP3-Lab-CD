{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurt1/AP3-Lab-CD/blob/main/An%C3%A1lise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vjwem2nXVx-E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ IDH-_Classificação.csv carregado com sucesso.\n",
            "✔ Densidade_Populacional_por_Bairros_(km²).csv carregado com sucesso.\n",
            "✔ Bairros_de_Fortaleza.csv carregado com sucesso.\n",
            "✔ Gravidez_na_Adolescência.csv carregado com sucesso.\n",
            "✔ Rede_Cuca.csv carregado com sucesso.\n",
            "✔ Equipamentos_de_Saúde.csv carregado com sucesso.\n",
            "✔ Areninhas.csv carregado com sucesso.\n",
            "✔ Pontos_de_Ônibus.csv carregado com sucesso.\n",
            "✔ Rede_Juv.csv carregado com sucesso.\n",
            "✔ Equipamentos_de_Assistência_Social.csv carregado com sucesso.\n",
            "Erro ao processar Rede_de_Esgoto.csv: No columns to parse from file\n",
            "✔ Assentamentos_Precários.csv carregado com sucesso.\n",
            "Erro ao processar Rede_de_Abastecimento_de_Água.csv: No columns to parse from file\n",
            "✔ Domicílios.csv carregado com sucesso.\n",
            "✔ CAPS-_Centros_de_Assistência_Psicossocial.csv carregado com sucesso.\n",
            "\n",
            "✅ Cabeçalhos salvos em /workspaces/AP3-Lab-CD/headers.json\n",
            "Processo concluído.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def main():\n",
        "    # Define o diretório de datasets\n",
        "    datasets_dir = Path(\"/workspaces/AP3-Lab-CD/Datasets\")\n",
        "\n",
        "    # Verifica se o diretório existe\n",
        "    if not datasets_dir.exists():\n",
        "        print(f\"O diretório {datasets_dir} não existe.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Lista para armazenar os cabeçalhos\n",
        "    all_headers = []\n",
        "\n",
        "    # Itera sobre todos os arquivos no diretório de datasets\n",
        "    for file_path in datasets_dir.glob(\"*.csv\"):\n",
        "        try:\n",
        "            # Tentando múltiplas codificações\n",
        "            encodings = [\"utf-8\", \"ISO-8859-1\", \"latin1\"]\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    # Lê apenas o cabeçalho para evitar carregar grandes arquivos\n",
        "                    df = pd.read_csv(file_path, encoding=encoding, nrows=1)\n",
        "                    headers = df.columns.tolist()\n",
        "                    \n",
        "                    # Se for um arquivo vazio, ignora\n",
        "                    if not headers:\n",
        "                        print(f\"Aviso: {file_path.name} está vazio. Ignorando.\")\n",
        "                        break\n",
        "                    \n",
        "                    # Adiciona ao JSON final\n",
        "                    all_headers.append({file_path.name: headers})\n",
        "                    print(f\"✔ {file_path.name} carregado com sucesso.\")\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue  # Tenta a próxima codificação\n",
        "            else:\n",
        "                print(f\"Erro: Não foi possível ler {file_path.name} com as codificações testadas.\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {file_path.name}: {e}\")\n",
        "\n",
        "    # Define o caminho de saída do JSON\n",
        "    output_path = datasets_dir.parent / \"headers.json\"\n",
        "\n",
        "    # Salva os cabeçalhos em um arquivo JSON\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(all_headers, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n✅ Cabeçalhos salvos em {output_path}\")\n",
        "    print(\"Processo concluído.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyObHy94NqyWFmVKnjBHm5Rl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
